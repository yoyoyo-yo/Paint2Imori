{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pix2pix_edge2akahara_tfkeras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu2Q9R4bansY"
      },
      "source": [
        "# pix2pix Edge > RGB, tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wYRvtdaaiBh"
      },
      "source": [
        "!pip install opencv-python #icrawler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAzmJYhqa29H"
      },
      "source": [
        "# Crawling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOotM6n2a182"
      },
      "source": [
        "# import os\n",
        "# import logging\n",
        "# import shutil\n",
        "# import requests\n",
        "# from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
        "\n",
        "# requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
        "\n",
        "# TRAIN_DATA_PATH = 'train_images'\n",
        "\n",
        "# if os.path.exists(TRAIN_DATA_PATH):\n",
        "#     shutil.rmtree(TRAIN_DATA_PATH)\n",
        "\n",
        "# os.makedirs(TRAIN_DATA_PATH, exist_ok=True)\n",
        "\n",
        "# from icrawler.builtin import BingImageCrawler\n",
        "# crawler = BingImageCrawler(storage={'root_dir': TRAIN_DATA_PATH}, parser_threads=2, downloader_threads=4, log_level=logging.CRITICAL)\n",
        "# crawler.session.verify = False\n",
        "# crawler.crawl(keyword=\"アカハライモリ\", max_num=1000, min_size=(100, 100), max_size=None, file_idx_offset=0)\n",
        "\n",
        "# # below is invalid 2020.5.6\n",
        "# #from icrawler.builtin import GoogleImageCrawler\n",
        "# #crawler = GoogleImageCrawler(storage={\"root_dir\": DIR_NAME})\n",
        "# #crawler.crawl(keyword=\"アカハライモリ\", max_num=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrY99zHkbYIY"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvVoq1ajbdoK"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe5hW_uGrtF5"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz3V3plmbZRa"
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86Ud-p8mbn8Q"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaEB2n24a5AO"
      },
      "source": [
        "Input_height = 256\n",
        "Input_width = 256\n",
        "Input_channel = 1 # Gray\n",
        "\n",
        "Output_channel = 3 # RGB\n",
        "\n",
        "Base_path = 'drive/My Drive/Colab Notebooks/tf_keras/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-LJ0NcwcwV8"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqSxeON4cw-j"
      },
      "source": [
        "def UNet():\n",
        "    def unet_encoder(x, filters, ksize=4, bn=False):\n",
        "        initializer = tf.random_normal_initializer(0., 0.02)\n",
        "        x = tf.keras.layers.Conv2D(filters, ksize, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(x)\n",
        "        #x = tf.keras.layers.ReLU()(x)\n",
        "        if bn:\n",
        "            x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.LeakyReLU()(x)\n",
        "        return x\n",
        "\n",
        "    def unet_decoder(x, filters, ksize=4, do=False):\n",
        "        initializer = tf.random_normal_initializer(0., 0.02)\n",
        "        x = tf.keras.layers.Conv2DTranspose(filters, ksize, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        if do:\n",
        "            x = tf.keras.layers.Dropout(0.5)(x)\n",
        "        x = tf.keras.layers.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    conv_dim = 16\n",
        "\n",
        "    _input = tf.keras.layers.Input(shape=[Input_height, Input_width, Input_channel])\n",
        "    x_enc1 = unet_encoder(_input, conv_dim, bn=False)\n",
        "    x_enc2 = unet_encoder(x_enc1, conv_dim * 2)\n",
        "    x_enc3 = unet_encoder(x_enc2, conv_dim * 4)\n",
        "    x_enc4 = unet_encoder(x_enc3, conv_dim * 8)\n",
        "    x_enc5 = unet_encoder(x_enc4, conv_dim * 8)\n",
        "    x_enc6 = unet_encoder(x_enc5, conv_dim * 8)\n",
        "    x_enc7 = unet_encoder(x_enc6, conv_dim * 8)\n",
        "    x_enc8 = unet_encoder(x_enc7, conv_dim * 8)\n",
        "\n",
        "    # up sample\n",
        "    x_dec7 = unet_decoder(x_enc8, conv_dim * 8, do=True)\n",
        "    x_dec7 = tf.keras.layers.concatenate([x_dec7, x_enc7])\n",
        "\n",
        "    x_dec6 = unet_decoder(x_dec7, conv_dim * 8, do=True)\n",
        "    x_dec6 = tf.keras.layers.concatenate([x_dec6, x_enc6])\n",
        "\n",
        "    x_dec5 = unet_decoder(x_dec6, conv_dim * 8, do=True)\n",
        "    x_dec5 = tf.keras.layers.concatenate([x_dec5, x_enc5])\n",
        "\n",
        "    x_dec4 = unet_decoder(x_dec5, conv_dim * 8)\n",
        "    x_dec4 = tf.keras.layers.concatenate([x_dec4, x_enc4])\n",
        "\n",
        "    x_dec3 = unet_decoder(x_dec4, conv_dim * 4)\n",
        "    x_dec3 = tf.keras.layers.concatenate([x_dec3, x_enc3])\n",
        "\n",
        "    x_dec2 = unet_decoder(x_dec3, conv_dim * 2)\n",
        "    x_dec2 = tf.keras.layers.concatenate([x_dec2, x_enc2])\n",
        "\n",
        "    x_dec1 = unet_decoder(x_dec2, conv_dim)\n",
        "    x_dec1 = tf.keras.layers.concatenate([x_dec1, x_enc1])\n",
        "    \n",
        "    x_out = tf.keras.layers.Conv2DTranspose(Output_channel, 4, strides=2, padding='same', activation='tanh')(x_dec1)\n",
        "    return tf.keras.Model(inputs=_input, outputs=x_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xac7NP5-wDV"
      },
      "source": [
        "def Discriminator():\n",
        "    def disc_encoder(x, filters, ksize, bn=True):\n",
        "        x = tf.keras.layers.Conv2D(filters, ksize, strides=2, padding='same', use_bias=False)(x)\n",
        "        if bn:\n",
        "            x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.LeakyReLU()(x)\n",
        "        return x\n",
        "\n",
        "    _input1 = tf.keras.layers.Input(shape=[Input_height, Input_width, Input_channel], name='input1')\n",
        "    _input2 = tf.keras.layers.Input(shape=[Input_height, Input_width, Output_channel], name='input2')\n",
        "    \n",
        "    x = tf.keras.layers.concatenate([_input1, _input2])\n",
        "    x = disc_encoder(x, 64, 5, bn=False)\n",
        "    x = disc_encoder(x, 128, 5)\n",
        "    x = disc_encoder(x, 256, 5)\n",
        "    x = disc_encoder(x, 512, 5)\n",
        "    x = tf.keras.layers.Conv2D(1, 5, strides=1, padding='same')(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=[_input1, _input2], outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLnJvNlyFDQX"
      },
      "source": [
        "# def UNet():\n",
        "#     def UNet_block_downSampling(x, filters, size, name, apply_batchnorm=False):\n",
        "#         x = tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', use_bias=False, name=name + '_conv')(x)\n",
        "#         #x = tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=tf.random_normal_initializer(0., 0.02), \n",
        "#         #                           use_bias=False, name=name + '_conv')(x)\n",
        "#         #x = tf.keras.layers.LeakyReLU(name=name + '_leakyReLU')(x) if apply_batchnorm else x\n",
        "#         x = tf.keras.layers.ReLU(name=name + '_ReLU')(x)\n",
        "#         x = tf.keras.layers.BatchNormalization(name=name + '_bn')(x)\n",
        "        \n",
        "#         return x\n",
        "\n",
        "#     def UNet_block_upSampling(x, filters, size, name, apply_dropout=False):\n",
        "#         x = tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same', use_bias=False, name=name + '_transposedConv')(x)\n",
        "#         #x = tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
        "#         #                                    use_bias=False, name=name + '_transposedConv')(x)\n",
        "#         #x = tf.keras.layers.ReLU(name=name + '_ReLU')(x)\n",
        "#         x = tf.keras.layers.BatchNormalization(name=name + '_bn')(x)\n",
        "#         x = tf.keras.layers.Dropout(0.5, name=name + 'dropout')(x) if apply_dropout else x\n",
        "        \n",
        "#         return x\n",
        "\n",
        "#     stride_N = int(np.log(Input_height) / np.log(2))\n",
        "\n",
        "#     x_encoders = []\n",
        "\n",
        "#     _input = tf.keras.layers.Input(shape=[Input_height, Input_width, Input_channel])\n",
        "#     # down sample\n",
        "#     x = _input\n",
        "#     for i in range(1, stride_N + 1):\n",
        "#         x = UNet_block_downSampling(x, min(64 ** i, 512), 3, name='Encoder{}'.format(i))\n",
        "#         x_encoders.append(x)\n",
        "#     \"\"\"\n",
        "#     x_encoder1 = UNet_block_downSampling(_input, 64, 4, apply_batchnorm=False, name='Encoder1') # (bs, 128, 128, 64)\n",
        "#     x_encoder2 = UNet_block_downSampling(x_encoder1, 128, 4, name='Encoder2') # (bs, 64, 64, 128)\n",
        "#     x_encoder3 = UNet_block_downSampling(x_encoder2, 256, 4, name='Encoder3') # (bs, 32, 32, 256)\n",
        "#     x_encoder4 = UNet_block_downSampling(x_encoder3, 512, 4, name='Encoder4') # (bs, 16, 16, 512)\n",
        "#     x_encoder5 = UNet_block_downSampling(x_encoder4, 512, 4, name='Encoder5') # (bs, 8, 8, 512)\n",
        "#     x_encoder6 = UNet_block_downSampling(x_encoder5, 512, 4, name='Encoder6') # (bs, 4, 4, 512)\n",
        "#     x_encoder7 = UNet_block_downSampling(x_encoder6, 512, 4, name='Encoder7') # (bs, 2, 2, 512)\n",
        "#     x_encoder8 = UNet_block_downSampling(x_encoder7, 512, 4, name='Encoder8') # (bs, 1, 1, 512)\n",
        "#     \"\"\"\n",
        "\n",
        "#     for i in range(stride_N - 1, 0, -1):\n",
        "#         x = UNet_block_upSampling(x, min(64 ** i, 512), 3, name='Decoder{}'.format(i - 1))\n",
        "#         x = tf.keras.layers.concatenate([x, x_encoders[i - 1]])\n",
        "\n",
        "#     # up sample\n",
        "#     \"\"\"\n",
        "#     x_decoder7 = UNet_block_upSampling(x_encoder8, 512, 4, apply_dropout=True, name='Decoder7') # (bs, 2, 2, 512)\n",
        "#     x_concat7 = tf.keras.layers.Concatenate()([x_decoder7, x_encoder7]) # (bs, 2, 2, 1024)\n",
        "#     x_decoder6 = UNet_block_upSampling(x_concat7, 512, 4, apply_dropout=True, name='Decoder6') # (bs, 4, 4, 512)\n",
        "#     x_concat6 = tf.keras.layers.Concatenate()([x_decoder6, x_encoder6]) # (bs, 4, 4, 1024)\n",
        "#     x_decoder5 = UNet_block_upSampling(x_concat6, 512, 4, apply_dropout=True, name='Decoder5') # (bs, 8, 8, 512)\n",
        "#     x_concat5 = tf.keras.layers.Concatenate()([x_decoder5, x_encoder5]) # (bs, 8, 8, 1024)\n",
        "#     x_decoder4 = UNet_block_upSampling(x_concat5, 512, 4, name='Decoder4') # (bs, 16, 16, 512)\n",
        "#     x_concat4 = tf.keras.layers.Concatenate()([x_decoder4, x_encoder4]) # (bs, 16, 16, 1024)\n",
        "#     x_decoder3 = UNet_block_upSampling(x_concat4, 256, 4, name='Decoder3') # (bs, 32, 32, 256)\n",
        "#     x_concat3 = tf.keras.layers.Concatenate()([x_decoder3, x_encoder3]) # (bs, 32, 32, 512)\n",
        "#     x_decoder2 = UNet_block_upSampling(x_concat3, 128, 4, name='Decoder2') # (bs, 64, 64, 128)\n",
        "#     x_concat2 = tf.keras.layers.Concatenate()([x_decoder2, x_encoder2]) # (bs, 64, 64, 256)\n",
        "#     x_decoder1 = UNet_block_upSampling(x_concat2, 64, 4, name='Decoder1') # (bs, 128, 128, 64)\n",
        "#     x_concat1 = tf.keras.layers.Concatenate()([x_decoder1, x_encoder1]) # (bs, 128, 128, 128)\n",
        "#     \"\"\"\n",
        "\n",
        "#     x_output = tf.keras.layers.Conv2DTranspose(Output_channel, 3, strides=2, padding='same', activation='tanh')(x)\n",
        "#     #x_output = tf.keras.layers.Conv2DTranspose(out_channel, 3, strides=2, padding='same',\n",
        "#     #                                     kernel_initializer=tf.random_normal_initializer(0., 0.02), activation='tanh')(x)\n",
        "#     return tf.keras.Model(inputs=_input, outputs=x_output)\n",
        "\n",
        "# def Discriminator():\n",
        "#     def Discriminator_block_downSampling(x, filters, size, name, apply_batchnorm=False):\n",
        "#         x = tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', use_bias=False, name=name + '_conv')(x)\n",
        "#         #x = tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=tf.random_normal_initializer(0., 0.02), \n",
        "#         #                           use_bias=False, name=name + '_conv')(x)\n",
        "#         #x = tf.keras.layers.BatchNormalization(name=name + '_bn')(x)\n",
        "#         x = tf.keras.layers.LeakyReLU(name=name + '_leakyReLU')(x) if apply_batchnorm else x\n",
        "#         return x\n",
        "\n",
        "#     stride_N = int(np.log(Input_height) / np.log(2))\n",
        "\n",
        "#     _input1 = tf.keras.layers.Input(shape=[Input_height, Input_width, Input_channel], name='input1')\n",
        "#     _input2 = tf.keras.layers.Input(shape=[Input_height, Input_width, Input_channel], name='input2')\n",
        "    \n",
        "#     x = tf.keras.layers.concatenate([_input1, _input2]) # (bs, 256, 256, channels*2)\n",
        "\n",
        "#     for i in range(1, stride_N):\n",
        "#         x = Discriminator_block_downSampling(x, min(64 ** i, 512), 5, name='D{}'.format(i))\n",
        "    \n",
        "#     x = tf.keras.layers.Conv2D(1, 2, strides=1, padding='same')(x)\n",
        "#     #x = tf.keras.layers.Conv2D(1, 2, strides=1, padding='same', kernel_initializer=tf.random_normal_initializer(0., 0.02))(x) # (bs, 30, 30, 1)\n",
        "\n",
        "#     return tf.keras.Model(inputs=[_input1, _input2], outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGQBDmcygzUV"
      },
      "source": [
        "# Utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrVW3nqAjfbt"
      },
      "source": [
        "class BatchGenerator():\n",
        "    def __init__(self, data_size, batch_size, shuffle=True):\n",
        "        self.data_size = data_size\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.mbi = 0 # index for iteration\n",
        "        self.inds = np.arange(data_size)\n",
        "        if shuffle:\n",
        "            np.random.shuffle(self.inds)\n",
        "\n",
        "    def __call__(self):\n",
        "        if self.mbi + self.batch_size > self.data_size:\n",
        "            inds = self.inds[self.mbi:]\n",
        "            if self.shuffle:\n",
        "                np.random.shuffle(self.inds)\n",
        "            inds = np.hstack((inds, self.inds[ : (self.batch_size - (self.data_size - self.mbi))]))\n",
        "            self.mbi = self.batch_size - (self.data_size - self.mbi)\n",
        "        else:\n",
        "            inds = self.inds[self.mbi : self.mbi + self.batch_size]\n",
        "            self.mbi += self.batch_size\n",
        "        return inds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UM5wiQcdL8w"
      },
      "source": [
        "def get_image(paths, aug_hflip=False, aug_vflip=False, aug_shift=False, aug_rot=False, aug_affine=False):\n",
        "    xs = []\n",
        "    xs_edge = []\n",
        "    \n",
        "    for path in paths:\n",
        "        x = cv2.imread(path.replace(\"/akahara_imori_seg/\", \"/akahara_imori/\").replace(\".png\", \".jpg\"))\n",
        "        x = x[..., ::-1] # BGR > RGB\n",
        "        x = cv2.resize(x, (Input_width, Input_height)) # resize\n",
        "\n",
        "        # get Edge\n",
        "        x_gray = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        x_gray = cv2.resize(x_gray, (Input_width, Input_height)) # resize\n",
        "\n",
        "        # if aug_hflip: # augmentation horizontal flip\n",
        "        #     if np.random.random() < 0.5:\n",
        "        #         x = x[:, ::-1]\n",
        "        #         x_seg = x_seg[:, ::-1]\n",
        "        \n",
        "\n",
        "        #x_gray = cv2.cvtColor(x_seg, cv2.COLOR_BGR2GRAY)\n",
        "        x_edge = cv2.Canny(x_gray, 100, 200)\n",
        "\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        x_edge = cv2.dilate(x_edge, kernel, iterations=1)\n",
        "        x_edge[x_edge > 0] = 255\n",
        "\n",
        "        # random drop pixel\n",
        "        # ind = np.random.rand(x_edge.shape[0], x_edge.shape[1])\n",
        "        # ind = (ind // 0.6).astype(bool)\n",
        "        # x_edge[ind] = 0\n",
        "        # random add pixel\n",
        "        # ind = np.random.rand(x_edge.shape[0], x_edge.shape[1])\n",
        "        # ind = (ind // 0.9).astype(bool)\n",
        "        # x_edge[ind] = 255\n",
        "\n",
        "\n",
        "        if aug_hflip:\n",
        "            if np.random.random() < 0.5:\n",
        "                x = x[:, ::-1]\n",
        "                x_edge = x_edge[:, ::-1]\n",
        "                x_gray = x_gray[:, ::-1]\n",
        "\n",
        "        if aug_vflip:\n",
        "            if np.random.random() < 0.5:\n",
        "                x = x[::-1]\n",
        "                x_edge = x_edge[::-1]\n",
        "                x_gray = x_gray[::-1]\n",
        "\n",
        "        if aug_shift:\n",
        "            M = np.float32([[1, 0, np.random.randint(-Input_width // 3, Input_width // 3)], [0, 1, np.random.randint(-Input_height // 3, Input_height // 3)]])\n",
        "            x = cv2.warpAffine(x, M, (x.shape[1], x.shape[0]))\n",
        "            x_edge = cv2.warpAffine(x_edge, M, (x_edge.shape[1], x_edge.shape[0]))\n",
        "            x_gray = cv2.warpAffine(x_gray, M, (x_edge.shape[1], x_edge.shape[0]))\n",
        "\n",
        "        if aug_rot:\n",
        "            M = cv2.getRotationMatrix2D((x.shape[1]/2, x.shape[0]/2), np.random.randint(-45, 45), 1)\n",
        "            x = cv2.warpAffine(x, M, (x.shape[1], x.shape[0]))\n",
        "            x_edge = cv2.warpAffine(x_edge, M, (x_edge.shape[1], x_edge.shape[0]))\n",
        "            x_gray = cv2.warpAffine(x_gray, M, (x_edge.shape[1], x_edge.shape[0]))\n",
        "\n",
        "        if aug_affine:\n",
        "            dis_h = Input_height // 4\n",
        "            dis_w = Input_width // 4\n",
        "            p_original = np.float32([[0, 0], [x.shape[0], 0], [0, x.shape[1]], [x.shape[0], x.shape[1]]])\n",
        "            p_trans = np.float32(\n",
        "                [[np.random.randint(dis_w), np.random.randint(dis_h)], \n",
        "                [x.shape[1] - np.random.randint(dis_w), np.random.randint(dis_h)], \n",
        "                [np.random.randint(dis_w), x.shape[0] - np.random.randint(dis_h)], \n",
        "                [x.shape[1] - np.random.randint(dis_w), x.shape[0] - np.random.randint(dis_h)]])\n",
        "            M = cv2.getPerspectiveTransform(p_original, p_trans)\n",
        "            x = cv2.warpPerspective(x, M, (x.shape[1], x.shape[0]))\n",
        "            x_edge = cv2.warpPerspective(x_edge, M, (x.shape[1], x.shape[0]))\n",
        "            x_gray = cv2.warpAffine(x_gray, M, (x_edge.shape[1], x_edge.shape[0]))\n",
        "\n",
        "        # masking\n",
        "        x_edge[x_edge > 0] = 255\n",
        "        x[x_gray == 0] = 255\n",
        "\n",
        "        xs.append(x)\n",
        "        xs_edge.append(x_edge)\n",
        "                \n",
        "    xs = np.array(xs, dtype=np.float32)\n",
        "    xs_edge = np.array(xs_edge, dtype=np.float32)\n",
        "\n",
        "    xs_edge = np.expand_dims(xs_edge, axis=-1)\n",
        "\n",
        "    # normalize\n",
        "    xs = xs / 127.5 - 1\n",
        "    xs_edge = xs_edge / 255\n",
        "\n",
        "    return xs, xs_edge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgSWnasDo50g"
      },
      "source": [
        "# get image path\n",
        "#img_paths = np.array(glob(f'{TRAIN_DATA_PATH}/*.jpg'))\n",
        "img_paths = np.array(glob(f'drive/My Drive/Colab Notebooks/Dataset/imori/akahara_imori_seg/*.png'))\n",
        "data_num = len(img_paths)\n",
        "print(f'data num >> {data_num}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv8YktlO8phi"
      },
      "source": [
        "# sample plot\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(get_image(img_paths[[i]])[1][0, ..., 0])\n",
        "    cv2.imwrite(f'drive/My Drive/Colab Notebooks/tf_keras/sample_input{i+1}.png', (get_image(img_paths[[i]])[1][0, ..., 0] * 255).astype(np.uint8))\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(get_image(img_paths[[i]])[0][0] * 0.5 + 0.5)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbuoR9e5Ulnm"
      },
      "source": [
        "x = cv2.imread(\"drive/My Drive/Colab Notebooks/Dataset/imori/akahara_imori/000041.jpg\")[..., ::-1]\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(x)\n",
        "    # M = np.float32([[1, 0, np.random.randint(-Input_width // 3, Input_width // 3)], [0, 1, np.random.randint(-Input_height // 3, Input_height // 3)]])\n",
        "    # x2 = cv2.warpAffine(x, M, (x.shape[1], x.shape[0]))\n",
        "    # M = cv2.getRotationMatrix2D((x.shape[1]/2, x.shape[0]/2), np.random.randint(-45, 45), 1)\n",
        "    # x2 = cv2.warpAffine(x, M, (x.shape[1], x.shape[0]))\n",
        "    p_original = np.float32([[0, 0], [x.shape[0], 0], [0, x.shape[1]], [x.shape[0], x.shape[1]]])\n",
        "    p_trans = np.float32(\n",
        "        [[np.random.randint(30), np.random.randint(30)], \n",
        "         [x.shape[0] - np.random.randint(30), np.random.randint(30)], \n",
        "         [np.random.randint(30), x.shape[1] - np.random.randint(30)], \n",
        "         [x.shape[0] - np.random.randint(30), x.shape[1] - np.random.randint(30)]])\n",
        "    M = cv2.getPerspectiveTransform(p_original, p_trans)\n",
        "    x2 = cv2.warpPerspective(x, M, (x.shape[1], x.shape[0]))\n",
        "    plt.subplot(1, 2 ,2)\n",
        "    plt.imshow(x2)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUG-_0stij5h"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl4eR_8GLv3V"
      },
      "source": [
        "# model\n",
        "G = UNet()\n",
        "print('Generator loaded')\n",
        "D = Discriminator()\n",
        "print('Discriminator loaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqy5WcdqMRF2"
      },
      "source": [
        "# optimizer\n",
        "G_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "D_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qDwATOMWsM"
      },
      "source": [
        "Loss_Lambda = 10.\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, target):\n",
        "    with tf.GradientTape() as G_tape, tf.GradientTape() as D_tape:\n",
        "        Gx = G(x, training=True)\n",
        "        D_real = D([x, target], training=True)\n",
        "        D_fake = D([x, Gx], training=True)\n",
        "\n",
        "        # Generator loss\n",
        "        G_loss_fake = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(D_fake), D_fake)\n",
        "        G_loss_L1 = tf.reduce_mean(tf.abs(target - Gx))\n",
        "        G_loss = G_loss_fake + Loss_Lambda * G_loss_L1\n",
        "\n",
        "        # Discriminator loss\n",
        "        D_loss_real = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(D_real), D_real)\n",
        "        D_loss_fake = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(D_fake), D_fake)\n",
        "        D_loss = D_loss_real + D_loss_fake\n",
        "\n",
        "    G_gradients = G_tape.gradient(G_loss, G.trainable_variables)\n",
        "    D_gradients = D_tape.gradient(D_loss, D.trainable_variables)\n",
        "\n",
        "    G_opt.apply_gradients(zip(G_gradients, G.trainable_variables))\n",
        "    D_opt.apply_gradients(zip(D_gradients, D.trainable_variables))\n",
        "\n",
        "    return {'G_loss' : G_loss, 'G_loss_fake' : G_loss_fake, 'G_loss_L1' : G_loss_L1,\n",
        "            'D_loss' : D_loss, 'D_loss_real' : D_loss_real, 'D_loss_fake' : D_loss_fake,\n",
        "            'Gx' : Gx\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WGzFm7NM_oL"
      },
      "source": [
        "# training parameter\n",
        "Iteration = 30_000\n",
        "Minibatch = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8rBOVUCNCy1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykk4tEhSik3O"
      },
      "source": [
        "# training\n",
        "pbar = ''\n",
        "\n",
        "\n",
        "# buffer\n",
        "# all_Xs, all_Xs_edge = get_image(img_paths)\n",
        "\n",
        "# all_Xs_2, all_Xs_edge_2 = get_image(img_paths, aug_hflip=True)\n",
        "# all_Xs_3, all_Xs_edge_3 = get_image(img_paths, aug_vflip=True)\n",
        "\n",
        "# all_Xs = np.vstack([all_Xs, all_Xs_2, all_Xs_3])\n",
        "# all_Xs_edge = np.vstack([all_Xs_edge, all_Xs_edge_2, all_Xs_edge_3])\n",
        "\n",
        "print('train start')\n",
        "\n",
        "# training\n",
        "batch_gen = BatchGenerator(len(img_paths), Minibatch) # all data num, minibatch\n",
        "\n",
        "for ite in range(Iteration):\n",
        "    # batch generate\n",
        "    mb_inds = batch_gen()\n",
        "    Xs, Xs_edge = get_image(img_paths[mb_inds], aug_hflip=True, aug_vflip=True, aug_shift=True, aug_rot=True)\n",
        "    # Xs = all_Xs[mb_inds]\n",
        "    # Xs_edge = all_Xs_edge[mb_inds]\n",
        "\n",
        "    # train step\n",
        "    res_dict = train_step(Xs_edge, Xs)\n",
        "\n",
        "    # show progress bar\n",
        "    pbar = pbar + f'|{ite + 1}'  if (ite + 1) % 10 == 0 else pbar + '|'\n",
        "    print(f'\\r{pbar}', end='')\n",
        "    \n",
        "    # show loss\n",
        "    if (ite + 1) % 100 == 0:\n",
        "        print('\\r' + ' ' * len(pbar), end='')\n",
        "        print(f\"\\riter : {ite + 1} G_Loss : {res_dict['G_loss']:.4f} fake : {res_dict['G_loss_fake']:.4f} , L1 : {res_dict['G_loss_L1']:.4f}, D_Loss : {res_dict['D_loss']:.4f} fake : {res_dict['D_loss_fake']:.4f} , real : {res_dict['D_loss_real']:.4f}\")\n",
        "        pbar = ''\n",
        "\n",
        "    # show sample\n",
        "    if (ite + 1) % 1_000 == 0:\n",
        "        Gxs = res_dict['Gx'] * 0.5  + 0.5\n",
        "        plt.subplot(1, 4, 1); plt.imshow(Xs_edge[0, ..., 0]); plt.title('input 1')\n",
        "        plt.subplot(1, 4, 2); plt.imshow(Gxs[0]); plt.title('output 1')\n",
        "        plt.subplot(1, 4, 3); plt.imshow(Xs_edge[1, ..., 0]); plt.title('input 2')\n",
        "        plt.subplot(1, 4, 4); plt.imshow(Gxs[1]); plt.title('output 2')\n",
        "        plt.show()\n",
        "\n",
        "    if (ite + 1) % 10_000 == 0:\n",
        "        G.save(f'{Base_path}/pix2pix_edge2akahara_g_iter{ite + 1}_model.h5')\n",
        "        # D.save_weights(f'{Base_path}/pix2pix_edge2akahara_d_iter{ite + 1}.h5')\n",
        "\n",
        "\n",
        "G.save_weights(f'{Base_path}/pix2pix_edge2akahara_iter{ite + 1}.h5')\n",
        "G.save(f'{Base_path}/pix2pix_edge2akahara_g_iter{ite + 1}_model.h5')\n",
        "D.save_weights(f'{Base_path}/pix2pix_edge2akahara_d_iter{ite + 1}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ltn4E3pswW"
      },
      "source": [
        "# G.load_weights(f'{Base_path}/pix2pix_edge2rgb_g_iter100000.h5')\n",
        "# G.save(f'{Base_path}/pix2pix_edge2rgb_g_iter100000_ver2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}